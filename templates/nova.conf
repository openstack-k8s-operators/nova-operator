{{define "nova-template"}}
[DEFAULT]
# concurrent live migrations are more likely to fail and are slower
# overall then serializing live migrations so set this to 1 explicitly
max_concurrent_live_migrations=1
state_path = /var/lib/nova
{{if eq .service_name "nova-api"}}
allow_resize_to_same_host = true
{{end}}
# enable log rotation in oslo config by default
max_logfile_count=1
max_logfile_size_mb=20
log_rotation_type=size
{{if (index . "log_file") }}
log_file = {{ .log_file }}
{{end}}
debug=true
{{if eq .service_name "nova-compute"}}
compute_driver = {{ .compute_driver }}
{{if eq .compute_driver "ironic.IronicDriver"}}
reserved_host_memory_mb = 0
{{end}}
{{ if (index . "enable_ceilometer") }}
instance_usage_audit = true
instance_usage_audit_period = hour
{{end}}
# ensure safe defaults for new hosts
initial_cpu_allocation_ratio=4.0
initial_ram_allocation_ratio=1.0
initial_disk_allocation_ratio=0.9
{{/*using a config drive will void issues with ovn and metadata*/}}
force_config_drive=True
mkisofs_cmd=/usr/bin/mkisofs
{{end}}
{{ if (index . "transport_url") }}
transport_url={{.transport_url}}
{{end}}
{{if eq .service_name "nova-api"}}
# scaling should be done by running more pods
osapi_compute_workers=1
enabled_apis=osapi_compute
{{else if eq .service_name "nova-metadata"}}
# scaling should be done by running more pods
metadata_workers=1
enabled_apis=metadata
{{end}}
{{if eq .service_name "nova-novncproxy"}}
{{ if (index . "SSLCertificateFile") }}
ssl_only=true
cert={{.SSLCertificateFile}}
key={{.SSLCertificateKeyFile}}
{{end}}
{{end}}

[oslo_concurrency]
lock_path = /var/lib/nova/tmp

[oslo_messaging_rabbit]
{{ if (index . "quorum_queues") -}}
rabbit_quorum_queue=true
rabbit_transient_quorum_queue=true
amqp_durable_queues=true
{{- else -}}
amqp_durable_queues=false
amqp_auto_delete=false
{{- end -}}
{{/*we might just want to make this always false*/}}
{{ if eq .service_name "nova-api"}}
# We cannot set this to true while is
# https://review.opendev.org/c/openstack/oslo.log/+/852443 is not used in the
# nova-api image otherwise logging from the heartbeat thread will cause hangs.
heartbeat_in_pthread=false
{{else}}
heartbeat_in_pthread=false
{{end}}

{{ if eq .service_name "nova-api"}}
[oslo_policy]
enforce_new_defaults=true
enforce_scope=true
policy_file=/etc/nova/policy.yaml
{{end}}

{{ if eq .service_name "nova-conductor"}}
[conductor]
# scaling should be done by running more pods
workers=1
{{end}}

{{ if eq .service_name "nova-scheduler"}}
[filter_scheduler]
available_filters = nova.scheduler.filters.all_filters
enabled_filters = AggregateInstanceExtraSpecsFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter,SameHostFilter,DifferentHostFilter,PciPassthroughFilter,NUMATopologyFilter
# until we can disable upcalls we can't turn this off by default
# track_instance_changes = false
shuffle_best_same_weighed_hosts = true

[scheduler]
max_attempts = 10
# scaling should be done by running more pods
workers = 1
limit_tenants_to_placement_aggregate=true
placement_aggregate_required_for_tenants=false
query_placement_for_routed_network_aggregates=true
query_placement_for_availability_zone=true
query_placement_for_image_type_support=true
enable_isolated_aggregate_filtering=true
image_metadata_prefilter=true

{{end}}

{{if eq .service_name "nova-novncproxy"}}
[console]
ssl_minimum_version=tlsv1_3
{{end}}

[api]
# for compatibility with older release we override the default
# to be the empty string. This ensures no domain suffix is added
# to the instance name.
dhcp_domain = ''
{{if eq .service_name "nova-api" "nova-metadata"}}
auth_strategy = keystone
{{ if eq .service_name "nova-metadata"}}
local_metadata_per_cell = {{ .local_metadata_per_cell }}
{{end}}
[oslo_middleware]
enable_proxy_headers_parsing = True
[wsgi]
api_paste_config = /etc/nova/api-paste.ini
{{end}}

{{ if (index . "notification_transport_url")}}
[notifications]
notify_on_state_change = vm_and_task_state
notification_format=both
# notification_format=both specific to ceilometer as it depends on unversioned notifications
# bug https://bugs.launchpad.net/ceilometer/+bug/1665449
# while other services support versioned
# so we emit both verioned and unversioned if notifications are enabled.
{{ end }}

[oslo_messaging_notifications]
{{ if (index . "notification_transport_url")}}
transport_url = {{.notification_transport_url}}
driver = messagingv2
{{ else }}
driver = noop
{{ end }}


{{ if eq .service_name "nova-novncproxy"}}
[vnc]
enabled = True
novncproxy_host = "::0"
novncproxy_port = 6080
{{if (index . "VencryptClientKey") }}
auth_schemes=vencrypt,none
vencrypt_client_key=/etc/pki/tls/private/vencrypt.key
vencrypt_client_cert=/etc/pki/tls/certs/vencrypt.crt
vencrypt_ca_certs=/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem
{{end}}
{{ else if and (eq .service_name "nova-compute") .vnc_enabled }}
[vnc]
enabled = True
novncproxy_base_url = {{ .novncproxy_base_url }}
server_listen = "::0"
{{/* https://docs.openstack.org/oslo.config/latest/configuration/format.html#substitution    */}}
# note we may want to use console_host instead of my_ip however it won't be resolved via
# dns currently so we need to use my_ip for now.
# https://docs.openstack.org/nova/latest/configuration/config.html#DEFAULT.console_host
server_proxyclient_address = "$my_ip"
{{else if and (eq .service_name "nova-compute") (not .vnc_enabled) }}
[vnc]
enabled = False
{{end}}

[cache]
# always enable caching
enabled = True
{{if (index . "MemcachedServers")}}
# on controller we prefer to use memcache when its deployed
{{if .MemcachedTLS}}
backend = oslo_cache.memcache_pool
memcache_servers={{ .MemcachedServers }}
memcache_socket_timeout = 0.5
memcache_pool_connection_get_timeout = 1
{{- if (index . "MemcachedAuthCert") }}
tls_certfile={{ .MemcachedAuthCert }}
tls_keyfile={{ .MemcachedAuthKey }}
tls_cafile={{ .MemcachedAuthCa }}
{{- end }}
{{else}}
backend = dogpile.cache.memcached
memcache_servers={{ .MemcachedServersWithInet }}
{{end}}
memcache_dead_retry = 30
tls_enabled={{ .MemcachedTLS }}
{{else}}
# on compute nodes or where memcache is not deployed we should use an in memory
# dict cache
backend = oslo_cache.dict
{{end}}

{{ if eq .service_name "nova-scheduler"}}
[workarounds]
disable_fallback_pcpu_query=true
{{end}}
{{ if eq .service_name "nova-compute"}}
[workarounds]
enable_qemu_monitor_announce_self=true
reserve_disk_resource_for_image_cache=true
# NOTE(gibi): We need this as live migration does not work with
# cpu_mode=host-model . See https://bugs.launchpad.net/nova/+bug/2039803
skip_cpu_compare_on_dest = true
{{end}}


{{ if eq .service_name "nova-compute" }}
{{ if eq .compute_driver "libvirt.LibvirtDriver" }}
[libvirt]
live_migration_permit_post_copy=true
live_migration_permit_auto_converge=true
live_migration_timeout_action=force_complete
cpu_mode=host-model
hw_machine_type=x86_64=q35
sysinfo_serial=unique
num_pcie_ports=24
images_type=qcow2
rx_queue_size=512
tx_queue_size=512
swtpm_enabled=True
volume_use_multipath=true
live_migration_uri = qemu+ssh://nova@%s/system?keyfile=/var/lib/nova/.ssh/ssh-privatekey
# We can only re-enable it when the following Jiras are fixed:
# https://issues.redhat.com/browse/OSPRH-8806
# https://issues.redhat.com/browse/OSPRH-8712
cpu_power_management=false
{{end}}
{{end}}

{{if (index . "cell_db_address")}}
[database]
connection = mysql+pymysql://{{ .cell_db_user }}:{{ .cell_db_password}}@{{ .cell_db_address }}/{{ .cell_db_name }}?read_default_file=/etc/my.cnf
{{end}}


{{if (index . "api_db_address")}}
[api_database]
connection = mysql+pymysql://{{ .api_db_user }}:{{ .api_db_password }}@{{ .api_db_address }}/{{ .api_db_name }}?read_default_file=/etc/my.cnf
{{end}}

[keystone_authtoken]
{{ if eq .service_name "nova-api"}}
www_authenticate_uri = {{ .www_authenticate_uri}}
{{end}}
{{if (index . "MemcachedServers")}}
memcached_servers={{ .MemcachedServers }}
{{end}}
auth_url =  {{ .keystone_internal_url }}
auth_type = password
project_domain_name = {{ .default_project_domain }}
user_domain_name = {{ .default_user_domain}}
project_name = service
username = {{ .nova_keystone_user }}
password = {{ .nova_keystone_password }}
region_name = {{ .openstack_region_name }}
# This is part of hardening related to CVE-2023-2088
# https://docs.openstack.org/nova/latest/configuration/config.html#keystone_authtoken.service_token_roles_required
# when enabled the service token user must have the service role to be considered valid.
service_token_roles_required = true
{{- if (index . "MemcachedAuthCert") }}
memcache_tls_certfile = {{ .MemcachedAuthCert }}
memcache_tls_keyfile = {{ .MemcachedAuthKey }}
memcache_tls_cafile = {{ .MemcachedAuthCa }}
memcache_tls_enabled = true
{{end}}

[placement]
auth_url =  {{ .keystone_internal_url }}
auth_type = password
project_domain_name = {{ .default_project_domain }}
user_domain_name = {{ .default_user_domain}}
project_name = service
username = {{ .nova_keystone_user }}
password = {{ .nova_keystone_password }}
region_name = {{ .openstack_region_name }}
valid_interfaces = internal

[glance]
auth_url = {{ .keystone_internal_url }}
auth_type = password
project_domain_name = {{ .default_project_domain }}
user_domain_name = {{ .default_user_domain}}
project_name = service
username = {{ .nova_keystone_user }}
password = {{ .nova_keystone_password }}
region_name = {{ .openstack_region_name }}
valid_interfaces = internal
{{if (index . "debug") }}debug=true{{end}}

[neutron]
auth_url = {{ .keystone_internal_url }}
auth_type = password
project_domain_name = {{ .default_project_domain }}
user_domain_name = {{ .default_user_domain}}
project_name = service
username = {{ .nova_keystone_user }}
password = {{ .nova_keystone_password }}
region_name = {{ .openstack_region_name }}
valid_interfaces = internal
{{if eq .service_name "nova-metadata"}}
metadata_proxy_shared_secret = {{ .metadata_secret }}
{{end}}
service_metadata_proxy = true

[cinder]
auth_url = {{ .keystone_internal_url }}
auth_type = password
project_domain_name = {{ .default_project_domain }}
user_domain_name = {{ .default_user_domain}}
project_name = service
username = {{ .nova_keystone_user }}
password = {{ .nova_keystone_password }}
os_region_name = {{ .openstack_region_name }}
catalog_info = volumev3:cinderv3:internalURL

[barbican]
auth_url =  {{ .keystone_internal_url }}
auth_type = password
project_domain_name = {{ .default_project_domain }}
user_domain_name = {{ .default_user_domain}}
project_name = service
username = {{ .nova_keystone_user }}
password = {{ .nova_keystone_password }}
barbican_region_name = {{ .openstack_region_name }}
barbican_endpoint_type = internal

[service_user]
send_service_user_token = true
auth_url = {{ .keystone_internal_url }}
auth_type = password
project_domain_name = {{ .default_project_domain }}
user_domain_name = {{ .default_user_domain}}
project_name = service
username = {{ .nova_keystone_user }}
password = {{ .nova_keystone_password }}

[oslo_limit]
system_scope = all
endpoint_interface = internal
endpoint_service_type = compute
endpoint_region_name = {{ .openstack_region_name }}
auth_url = {{ .keystone_internal_url }}
auth_type = password
user_domain_name = {{ .default_user_domain}}
username = {{ .nova_keystone_user }}
password = {{ .nova_keystone_password }}

{{ if (index . "compute_driver") }}
{{if eq .compute_driver "ironic.IronicDriver"}}
[ironic]
auth_type = password
auth_url = {{ .keystone_internal_url }}
project_name = service
username = {{ .nova_keystone_user }}
password = {{ .nova_keystone_password }}
project_domain_name = {{ .default_project_domain }}
user_domain_name = {{ .default_user_domain}}
region_name = {{ .openstack_region_name }}
{{ end }}
{{ end }}

[upgrade_levels]
compute = auto

[oslo_reports]
# api services need file based GMR trigger as apache disables signal handling
file_event_handler=/var/lib/nova
{{end}}
{{- $var := execTempl "nova-template" . | removeNewLinesInSections -}}
{{$var -}}
